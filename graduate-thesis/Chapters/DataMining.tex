\chapter{Data Processing Methods}
\label{ch:mining}

This chapter introduces the data processing method used in this study, mainly about data preparing (including clean and transformation), reduction (PCA) and learning algorithm.

\section{Data Preparing}

\subsection{Data Clean}
As a real-world applications of data mining, there are some invalid or missing data in the original data collection. This system should automatically remove invalid data from the raw data and replace missing values with rational information. The rule to handle data is as follows,

\begin{itemize}
	\item Data on holiday. One example is in figure~\ref{fg:invalid_data}, Jan 1, 2016 is New Year Day, and Dec 25, 2015 is Christmas day. There are no transactions on these two days, but in Yahoo Finance, holidays like there are still listed there. Information about Hong Kong holidays are collected from http://www.timeanddate.com/, and after downloading data from Yahoo Finance, the system would automatically remove these holiday transaction data.
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.9\textwidth]{invalid-data}
		\caption{Example for invalid data}
		\label{fg:invalid_data}
	\end{figure}
	\item Missing data. Like figure~\ref{fg:missing_data}, the overnight and 1-week rate is inaccessible on that day. In this case, the system would automatically use valid previous information to instead this value.
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.6\textwidth]{missingdata}
		\caption{Example for missing data}
		\label{fg:missing_data}
	\end{figure}
	\item Time difference. This is a big issue when the system queries some data based on different time zone from Hong Kong Time (HKT, GMT+8), e.g. New York time (GMT -4), which is 12 hours behind HKT. Obviously, at the beginning of each transaction day in Hong Kong, it is impossible to get the same day information in NY. Thus, the date of data at NYT should be one day prior to that in HKT.
\end{itemize}


The above are data cleaning rules in this system, and after the above processing, clean data would do the following step, normalization.

\subsection{Data Transformation}


The main objective of data normalizations is to guarantee the quality of the data before it is imported to learning methods, as if using non-normalized data, the algorithm may overweight those features with larger values, or underestimate those with smaller values. Data normalization can also speed up training process because in the initial, each feature is in the same scale.\\


In this study two normalization methods are mainly used to ensure the data is in same scale.


\subsubsection{Min-Max Normalization}
This technique obtains distribution of values on a predefined normalized interval, for example [0, 1], or [-1, 1]. In this study, the data range is usually [-1, 1], formula used here is,


\begin{equation}
v'(i)=\frac{2\times v(i)- (max(v(i))+min(v(i)))}{max(v(i))-min(v(i))}
\end{equation}


The problem of using min-max normalization method in stock price prediction is that the minimum and maximum values of out-of-sample data remain unknown at start. \\


To solve this problem, the maximum and minimum value used in this system is the highest and lowest price over the last 5 days. It is true that if the price keeps going up or down in the time period (including the predicting day), the normalized value may larger than 1 or smaller than -1.


\subsubsection{Standard Deviation Normalization}


Standard deviation normalization often works well in scale measures but transforms the original data into a different form, i.e., this type of normalization changes the pattern of original data. In this study, the equation of Standard Deviation is as below,


\begin{equation}
v'(i)=\frac{v(i)-mean(v)}{std(v)}
\end{equation}


This normalization method shares same problem with min-max, the mean average and standard deviation of out-of-sample data is unknown. \\


To avoid this problem, in this experiment, standard deviation normalization is mainly used to normalize the absolute difference value of price.


\subsubsection{Sigmoid Normalization\cite{nayak2014impact}}
This normalization method is used in the training process of Artificial Neural Network. The data value $v$ is computed through,


\begin{equation}
v'(i)=\frac{1}{1+e^{v(i)}}
\end{equation}

One advantage of this type of normalization is that no previous knowledge of data is needed. But it is not suitable to transform raw data directly as the scale of original is a little large.

\section{Principal Components Analysis}

To interpret a large dataset in a more meaningful form, it is necessary to reduce the number of variables to a few, interpretable linear combinations of the data. PCA is probably the most widely-used and well-known of the “standard” multivariate methods. PCA first invented by Pearson \cite{peason1901lines}, is a useful tool to extract relevant information from data sets, and provides a method to reduce a complex data set to a lower dimension. Practical applications confirmed that PCA is the best linear dimension-reduction technique in the mean-square-error sense.\cite{4_kantardzic}. \\

PCA takes a data matrix of n objects by p variables, which may be correlated, and summarizes it by uncorrelated axes (principal components or principal axes) that are linear combinations of the original p variables. The first k components display as much as possible of the variation among objects.

\subsection{Procedure of PCA\cite{4_kantardzic}}

Suppose that we have a random vector $\textbf{X}$.
\begin{equation}
\textbf{X} = \left(\begin{array}{c} X_1\\ X_2\\ \vdots \\X_p\end{array}\right)
\end{equation}
Our goal is to develop a new set of p axes (linear combinations of the original p axes) in the directions of greatest variability, as Figure~\ref{fg:pca_pitcure} shows. This goal is accomplished by rotating the axes.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{pca-picture}
	\caption{Rotating the axes}
	\label{fg:pca_pitcure}
\end{figure}

Suppose our vector with covariance matrix $\Sigma$
\begin{equation}
\text{var}(\textbf{X}) = \Sigma = \left(\begin{array}{cccc}\sigma^2_1 & \sigma_{12} & \dots &\sigma_{1p}\\ \sigma_{21} & \sigma^2_2 & \dots &\sigma_{2p}\\  \vdots & \vdots & \ddots & \vdots \\ \sigma_{p1} & \sigma_{p2} & \dots & \sigma^2_p\end{array}\right)
\end{equation}

And eigenvalues $ \lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_p $ \\

We have to construct p linear combinations

\begin{equation}
\text{var}(\textbf{X}) = \Sigma = \left(\begin{array}{cccc}\sigma^2_1 & \sigma_{12} & \dots &\sigma_{1p}\\ \sigma_{21} & \sigma^2_2 & \dots &\sigma_{2p}\\  \vdots & \vdots & \ddots & \vdots \\ \sigma_{p1} & \sigma_{p2} & \dots & \sigma^2_p\end{array}\right)
\end{equation}

Note that $ Y_i $ is a function of our random data, and is also stochastic. Therefore it has a population variance
\begin{equation}
\begin{array}{lll} 
Y_1 & = & e_{11}X_1 + e_{12}X_2 + \dots + e_{1p}X_p \\ Y_2 & = & e_{21}X_1 + e_{22}X_2 + \dots + e_{2p}X_p \\ & & \vdots \\ Y_p & = & e_{p1}X_1 + e_{p2}X_2 + \dots +e_{pp}X_p
\end{array}
\end{equation}

Moreover, $ Y_i $ and $ Y_j $ have a population covariance

\begin{equation}
\text{cov}(Y_i, Y_j) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{ik}e_{jl}\sigma_{kl} = \mathbf{e}'_i\Sigma\mathbf{e}_j
\end{equation}

The coefficients $ e_{ij} $ are collected into the vector

\begin{equation}
\mathbf{e}_i = \left(\begin{array}{c} e_{i1}\\ e_{i2}\\ \vdots \\ e_{ip}\end{array}\right)
\end{equation}

The principal components are those uncorrelated linear combinations $ Y_1,\dots,Y_p $ whose variances are as large as possible. 
Then the first principal component is the linear combination of maximum variance, i.e.
\begin{equation}
\text{var}(Y_1) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{1k}e_{1l}\sigma_{kl} = \mathbf{e}'_1\Sigma\mathbf{e}_1
\end{equation}

subject to the constraint that
\begin{equation}
\mathbf{e}'_1\mathbf{e}_1 = \sum_{j=1}^{p}e^2_{1j} = 1
\end{equation}

The second principal component is the linear combination of maximum variance that is uncorrelated with the first principal component. Which means that we should select $ e_{21}, e_{22}, \dots, e_{2p} $ that maximizes the variance of this new component

\begin{equation}
\text{var}(Y_2) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{2k}e_{2l}\sigma_{kl} = \mathbf{e}'_2\Sigma\mathbf{e}_2
\end{equation}
subject to the constraint that the sums of squared coefficients add up to one,
\begin{equation}
\mathbf{e}'_2\mathbf{e}_2 = \sum_{j=1}^{p}e^2_{2j} = 1
\end{equation}
along with the additional constraint that these two components will be uncorrelated with one another.
\begin{equation}
\text{cov}(Y_1, Y_2) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{1k}e_{2l}\sigma_{kl} = \mathbf{e}'_1\Sigma\mathbf{e}_2 = 0
\end{equation}
All the subsequent principal components are linear combinations that account for as much of the remaining variation as possible with the constraint that not correlated with other principal components.\\
For the $ i^{th} $ principal component $ Y_i $ we should select $ e_{i1}, e_{i2}, \dots, e_{ip} $ that maximizes the variance of this new component

\begin{equation}
\text{var}(Y_i) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{ik}e_{il}\sigma_{kl} = \mathbf{e}'_i\Sigma\mathbf{e}_i
\end{equation}

subject to the constraint that sums of squared coefficients add up to one, along with the additional constraint that this new component will be uncorrelated with all the previously defined components.

\begin{gather*}
\mathbf{e}'_i\mathbf{e}_i = \sum_{j=1}^{p}e^2_{ij} = 1\\
\text{cov}(Y_1, Y_i) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{1k}e_{il}\sigma_{kl} = \mathbf{e}'_1\Sigma\mathbf{e}_i = 0\\
\text{cov}(Y_2, Y_i) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{2k}e_{il}\sigma_{kl} = \mathbf{e}'_2\Sigma\mathbf{e}_i = 0\\
\vdots\\
\text{cov}(Y_{i-1}, Y_i) = \sum_{k=1}^{p}\sum_{l=1}^{p}e_{i-1,k}e_{il}\sigma_{kl} = \mathbf{e}'_{i-1}\Sigma\mathbf{e}_i = 0
\end{gather*}

The following figure shows the visualization before and after PCA.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{pca-transform}
	\caption{Data visualization before and after PCA transformation\cite{6_tan_steinbach_kumar_2005}}
\end{figure}


\section{Supervised Learning Method}

This chapter introduces the learning method used in this dissertation, includes random forest, linear regression, artificial neural network (ANN), supported vector machine (SVM) and logistic regression. Except ANN, other learning method are the native library of Spark MLlib.\\


An agent is learning if it can improve its performance on future tasks through current experience\cite{russell2003artificial}. In this study, the system can learn a model through previous stock price, and used to predict future changes.\\


Machine Learning algorithms can be classified into three groups\cite{russell2003artificial}, 
\begin{enumerate}
	\item \textit{Reinforcement learning}: the agent learns from a series of reinforcements-rewards or punishments. For example, an student learns to be punctual to school after get punished of late.
	\item \textit{Unsupervised learning}: Given a lot of data, let the agent itself to infer a function to description hidden information from those.
	\item \textit{Supervised learning}: This is the main algorithm using in this study. Every training data contains input variables (also called features), and its outcome (also called label). supervised learning learns from a set of such type data, to a function h (also called hypothesis).
\end{enumerate}


In this study, the label of every sample is tomorrow's stock price, changing direction or differential amount, the features are those parameters mentioned in Chapter~\ref{ch:market}.\\


When the target variable that we're trying to predict is continuous, e.g. predicting tomorrow's stock price, we call this type of problem as \textbf{regression} problem. On the other hand, if the target variable only have a small number of discrete values (such as stock price changing direction, up or down), we call it a \textbf{classification} problem.


\subsection{Linear Model}
Regression method are mainly used to predict stock price or its changing amount in combined system.

\subsubsection{Linear Regression}
Linear regression can be defined using the following equation,
\begin{equation}
	y=w^Tx + \varepsilon
\end{equation}
$ w $ is called \emph{weights}, and $ x $ is features vector, y is target variable, and $ \varepsilon $ is called error term. One example of linear regression can be found in figure~\ref{fg:linear_regression}. This algorithm assumes that the relationship between features and label follows a linear model.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{Linear-regression}
	\caption{Example of simple linear regression with one variable}
	\label{fg:linear_regression}
\end{figure}


There are a large number of procedures which have been developed for parameters estimation and inference in linear regression. Spark MLlib uses least-square estimation\cite{7_mllib_linear_methods}.\\


Given a training set $ (x, y) $ (set number is $ n $), and initial weights $ w $, the error is computed as
\begin{equation}
error := \frac{1}{2} (w^T x - y)^2.
\label{eq:error_equation}
\end{equation}
This type of error is known as mean squared error (MSE).\\


After known the error, next step is using \emph{gradient descent} algorithm to update weight. Update equation is,
\begin{equation}
w_i=w_i-\alpha \frac{\partial}{\partial w_i} error
\label{eq:update_equation}
\end{equation}
Here $ \alpha $ is called learning rate. 


From above equation we can get that,
\begin{equation}
\begin{split}
\frac{\partial }{\partial w_i} error & = \frac{\partial }{\partial w_i} \frac{1}{2}(w^Tx-y)^2\\
& = 2 \cdot \frac{1}{2} (w^Tx-y) \cdot \frac{\partial }{\partial w_i} (w^Tx-y)\\
& = (w^Tx-y) * \frac{\partial }{\partial w_i} (\sum_{j=0}^{n}w_j x_j - y)\\
& = (w^Tx-y)x_i
\end{split}
\label{eq:partil_error}
\end{equation}


Then the updating rule becomes
\begin{equation}
w_i = w_i + \alpha (w^Tx-y)x_i
\end{equation}

This is gradient descent, also called batch gradient descent, the illustration is as figure~\ref{fg:gradient_descent}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{steepest-descent}
	\caption{Illustration of gradient descent}
	\label{fg:gradient_descent}
\end{figure}

This algorithm runs very slow for a large data set input, as in every iteration, the errors of every data pair should be calculated.\\


Spark MLlib use \emph{stochastic gradient descent (SGD)} to speed up the training process\cite{7_mllib_linear_methods}.\\


The core idea of SGD is that updating parameters according to the gradient of the error with respect to that a small sample of training example (even one). The illustration of SGD can be found in figure~\ref{fg:SGD}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{sgd}
	\caption{Illustration of stochastic gradient descent (SGD)}
	\label{fg:SGD}
\end{figure}
Usually, SGD gets $ w $ "close" to the optimal solution more faster than batch gradient descent\cite{bottou2010large}, (but may never reach that solution), this makes SGD more suitable to large scale data regression.\\


In this study, the training iterations of our linear regression model are set to 100000, while the learning rate is 0.001.

\subsubsection{Linear Support Vector Machines (SVMs)}
SVMs was developed by Vladimir Vapnik\cite{cortes1995support} and is one of the most popular supervised learning methods. This study uses SVM to solve the classification of stock change direction, a typical 2-class classification problem.\\


Without loss of generality, let's using a simple 2-D example to illustrate this problem. Assume we have a set of data, and we want to classify them into two categorical classes. As figure~\ref{fg:SVM} shows, there exits two possible parting lines with different boundary sizes. Are these decision boundaries equally good?
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{svms}
	\caption{Illustration of service vector machines\cite{8_svm_2016}}
	\label{fg:SVM}
\end{figure}
The main idea of SVM is: "The decision boundary should be as far away as possible from the data points of both class"\cite{4_kantardzic}. Based one the above idea, A is a better parting line than B (in figure~\ref{fg:SVM}).\\


Mathematica description is as follows. Given a classification problem with a training set $ D $, belongs to two classes (using binary with -1 and 1)
\begin{equation}
D={(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)},x\in R^n, y\in{-1, 1},
\end{equation}
The hyperplane can be represented as
\begin{equation}
w^T \cdot x+b=0
\end{equation}
This means that
\begin{align*}
w^T\cdot x_i+b>0,& \text{if $y_i = 1$}\\
w^T\cdot x_i+b<0,& \text{if $y_i = -1$}
\end{align*}
Then margin can be mathematically expressed as the following equation\cite{6_tan_steinbach_kumar_2005}
\begin{equation}
margin=\min_{i=1,\dots,n}y_i\cdot(\frac{w^T\cdot x_i}{\lVert w\rVert} +\frac{b}{\lVert w\rVert})
\end{equation}
Then next step is to find the maximum margin.\\


However, in real-world applications, there are the cases where subsets cannot be completely separated (like figure~\ref{fg:SVM_soft})\cite{4_kantardzic}. In other words, the algorithm would find a balance between maximizing the margin and minimizing the classifications error during optimization process.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{svm_soft}
	\caption{Soft margin of SVMs}
	\label{fg:SVM_soft}
\end{figure}

\subsubsection{Logistic Regression}
Logistic is also a widely used method to predict binary responses. Rather than predicting the value of the dependent variable in linear regression, logistic regression method estimates the probability that the dependent variable will choose from a given range\cite{4_kantardzic}.

 
Logistic regression takes probabilities of every label into consideration. Suppose that output Y has two possible values, 0 and 1. In training set, the possibilities can be expressed as: $ P(y_i=0)=1-p_i $ and $ P(y_i=1)=p_i $, then the \textit{linear logistic model} can be represented by~\cite{4_kantardzic},
\begin{equation}
	\log (\frac{p_i}{1-p_i}) = b + w^T \cdot x_i
\end{equation}
The reason for using the logit form of output is to prevent the model from generating a result out-range of $ [0, 1] $\\


In this system, logistic regression algorithm are mainly used to predict the changing direction of stock price.

\subsection{Random Forest}
Random forest algorithm was first created by Tin Kam Ho\cite{ho1995random} and is based on decision trees. To reduce the risk of overfitting, random forests composes of a number of individual decision trees, and this is also where this method get its name from (as figure~\ref{fg:decision-tree} shows).
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{random-forest}
	\caption{Illustration of random forest}
	\label{fg:decision-tree}
\end{figure}

Random Forest can solve both classification and regression problems. For the former problem, every decision tree's prediction is counted as a vote for one class, and the final result is the class that received most votes (like figure~\ref{fg:decision-tree}). For the later question, final result this the average of all decision trees' prediction value.\\


As every decision tree are trained and predicted separately, they can work in parallel, which makes random forest a very suitable algorithm for distributed computing.


\subsection{Artificial Neural Network}
Neural networks was first inspired by human nervous system which is made up of neurons, a information processing unit (figure~\ref{fg:neural-nework}). Every neuron receive signals from input or former neurons, then compute them with the activation function and send its result to output or latter neurons\cite{russell2003artificial}.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{neural_network}
	\caption{Illustration of Artificial Neural Network with one hidden layer}
	\label{fg:neural-nework}
\end{figure}

This study focus on back propagation MLP. The steps of algorithm can be described as follow\cite{russell2003artificial}:
\begin{enumerate}
	\item \textit{Initialize weights $ w $ with a small random value}. Suppose layer $ j $ has $ m $ nodes, layer $j + 1$ has $ n $ nodes, then the weight matrix between these two layer $ w_{jj+1} $ should have $ m \times n $.
	\item \textit{Forward Propagation}. The values of every layer $ i $ remark as $ l_i $ (Input as $ l_i =l_1 $, output as $l_o=l_n$, suppose there are n layers in total), the node $ k $ in $ l_j $ remark as $ l_jk $. Given the activation function
	\begin{equation}
	f(l) = \frac{1}{1+e^{-l}}
	\end{equation}
	the value of layer $ i + 1 $ is calculated by,
	\begin{equation}
	l_{i+1}=f(w_{ii+1}^T\cdot l_i)
	\end{equation}
	From the input layer, do this calculation. Record those values as $ l = [l_i, l_2, \ldots, l_o] $.
	\item \textit{Back Propagation and weights update} 
	\begin{enumerate}
		\item Get the error value using
		\begin{equation}
		\delta_n = y - l_n
		\end{equation}
		
		\item For the following layers, using formula,
		\begin{equation}
		\delta_j = w_{jj+1}^T\delta_{j+1}\cdot f'(l_i)
		\end{equation}
		where $ f'(l) = f(l)(1-f(l)) $
		
		\item Update weights.
		\begin{equation}
		w_{ii+1} = w_{ii+1} + \alpha \delta_i 
		\end{equation}
	\end{enumerate}
\end{enumerate}

The above algorithm is a typical batch gradient descent process. As data amount is relatively small (e.g. 1 year only have around 250 transaction days), using this method is much faster to reach the optimal solution.
