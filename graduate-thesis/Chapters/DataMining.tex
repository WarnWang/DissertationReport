\chapter{Data Processing Methods}
\label{ch:mining}

This chapter introduces the data processing method used in this study, mainly about data preparing (including clean and transformation), reduction (PCA) and learning algorithm.

\section{Data Preprocessing}

The section describes two preprocessing methods before we start to mining knowledge from input. The first is data clean rules used in this study, the second is data normalization.

\subsection{Data Clean}
As a real-world applications of data mining, there are some invalid or missing data in the original data collection. In this study, the collected raw data also contains some kind of error data, which would affect the prediction performance. Examples of such data and the processing method is shown in below,

\begin{itemize}
	\item Data on holiday. One example is in figure~\ref{fg:invalid_data}, Jan 1, 2016 is New Year Day, and Dec 25, 2015 is Christmas day. There are no transactions on these two days, but in Yahoo Finance, holidays like there are still listed there. Information about Hong Kong holidays are collected from http://www.timeanddate.com/, and after downloading data from Yahoo Finance, the system would automatically remove these holiday transaction data.
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.9\textwidth]{invalid-data}
		\caption{Example for invalid data}
		\label{fg:invalid_data}
	\end{figure}
	\item Missing data. Like figure~\ref{fg:missing_data}, the overnight and 1-week rate is inaccessible on that day. In this case, the system would automatically use valid previous information to instead this value.
	\begin{figure}[h]
		\centering
		\includegraphics[width=0.6\textwidth]{missingdata}
		\caption{Example for missing data}
		\label{fg:missing_data}
	\end{figure}
	\item Time difference. This is a big issue when the system queries some data based on different time zone from Hong Kong Time (HKT, GMT+8), e.g. New York time (GMT -4), which is 12 hours behind HKT. Obviously, at the beginning of each transaction day in Hong Kong, it is impossible to get the same day information in NY. Thus, the date of data at NYT should be one day prior to that in HKT.
\end{itemize}


The above are data cleaning rules in this system, and after the above processing, clean data would do the following step, normalization.

\subsection{Data normalizations}


The main objective of data normalizations is to guarantee the quality of data before it is imported to learning methods, as if using non-normalized data, some algorithms (like linear regression and Artificial Neural Network) may overweight those features with larger values, or underestimate those with smaller values. Data normalization can also speed up training process because in the initial, each feature is in the same scale.\\

In this study two normalization methods are mainly used to ensure the data is in same scale.


\subsubsection{Min-Max Normalization}
This technique obtains distribution of values on a predefined normalized interval, for example [0, 1], or [-1, 1]. In this study, the data range is usually [-1, 1], formula used here is\cite{nayak2014impact},


\begin{equation}
v'(i)=\frac{2\times v(i)- (max(v(i))+min(v(i)))}{max(v(i))-min(v(i))}
\end{equation}


The problem of using min-max normalization method in stock price prediction is that the minimum and maximum values of out-of-sample data remain unknown at start. \\

To solve this problem, the maximum and minimum value used in this system is the highest and lowest price over the last 5 days. It is true that if the price keeps going up or down in the time period (including the predicting day), the normalized value may larger than 1 or smaller than -1.


\subsubsection{Standard Deviation Normalization}


Standard deviation normalization often works well in scale measures but transforms the original data into a different form, i.e., this type of normalization changes the pattern of original data. In this study, the equation of Standard Deviation is as below\cite{nayak2014impact},

\begin{equation}
v'(i)=\frac{v(i)-mean(v)}{std(v)}
\end{equation}

This normalization method shares same problem with min-max, the mean average and standard deviation of out-of-sample data is unknown.\\

To avoid this problem, in this experiment, standard deviation normalization is mainly used to normalize the absolute difference value of price.

\subsubsection{Sigmoid Normalization}
\label{subsubsec:sigmoid}
This normalization method is used in the training process of Artificial Neural Network. The data value $v$ is computed through\cite{nayak2014impact},

\begin{equation}
v'(i)=\frac{1}{1+e^{v(i)}}
\end{equation}

One advantage of this type of normalization is that no previous knowledge of data is needed. But it is not suitable to transform raw data directly as the scale of original is a little large.

\section{Principal Components Analysis (PCA)}
To interpret a large dataset in a more meaningful form, it is necessary to reduce the number of variables to a few, interpretable linear combinations of the data. PCA is probably the most widely-used and well-known of the “standard” multivariate methods. PCA is a useful tool to extract relevant information from data sets, and provides a method to reduce a complex data set to a lower dimension. Practical applications confirmed that PCA is the best linear dimension-reduction technique in the mean-square-error sense\cite{4_kantardzic}.\\


PCA are based on the following assumptions\cite{shlens2014tutorial},
\begin{itemize}
	\item \emph{Linearity}. PCA re-expresses the data as a linear combination of its basis vectors. Let $ X $ be the original data set, $ Y $ be the transformed data set. The objective of PCA is to find a linear transform matrix $ P $ such that
	\begin{equation}
	PX=Y
	\end{equation}
	\item \emph{Mean and variance are fully observed}. This means that the input data can describe a probability distribution, which can make sure that the covariance and the SNR fully characterize the noise and redundancies.
	\item \emph{Principal components are orthogonal}. PCA assumes that all bias vectors $ {p_1, p_2, \ldots, p_m} $ in $ P $ are orthogonal, and that the directions with the largest variances are the first principal components.
\end{itemize}

The process of performing PCA can be summarized as\cite{shlens2014tutorial},
\begin{enumerate}
	\item Use an $ m \times n $ matrix to represent the original data set, where $ m $ is the number of dimensions of input data types, $ n $ is the number of input data row vectors;
	\item Every input data vector subtract the mean vector for every data types;
	\item Use singular value decomposition or eigenvectors of covariance to solve PCA;
	\item Utilize $ P $ from last step to calculate $ Y $.
\end{enumerate}

PCA is a \emph{non-parametric} analysis, which means that there is no need to tweak parameters based on user experience\cite{shlens2014tutorial}. This characteristic makes it very useful suitable for this project, as I have no former experience about those data.\\

The PCA transformer used in this project is a method of ``sklearn'' package, the parameter are just the default showed on the website\footnote{The details about this function can be found on the official document in http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html}.

\section{Supervised Learning Method}

This chapter introduces the learning method used in this dissertation, includes random forest, linear regression, artificial neural network (ANN), supported vector machine (SVM) and logistic regression. Except ANN, other learning method are the native library of Spark MLlib.\\


An agent is learning if it can improve its performance on future tasks through current experience\cite{russell2003artificial}. In this study, the system can learn a model through previous stock price, and used to predict future changes.\\


Machine Learning algorithms can be classified into three groups\cite{russell2003artificial}, 
\begin{enumerate}
	\item \textit{Reinforcement learning}: the agent learns from a series of reinforcements-rewards or punishments. For example, an student learns to be punctual to school after get punished of late.
	\item \textit{Unsupervised learning}: Given a lot of data, let the agent itself to infer a function to description hidden information from those.
	\item \textit{Supervised learning}: This is the main algorithm using in this study. Every training data contains input variables (also called features), and its outcome (also called label). supervised learning learns from a set of such type data, to a function h (also called hypothesis).
\end{enumerate}


In this study, the label of every sample is tomorrow's stock price, changing direction or differential amount, the features are those parameters mentioned in Chapter~\ref{ch:market}.\\


When the target variable that we're trying to predict is continuous, e.g. predicting tomorrow's stock price, we call this type of problem as \textbf{regression} problem. On the other hand, if the target variable only have a small number of discrete values (such as stock price changing direction, up or down), we call it a \textbf{classification} problem.


\subsection{Linear Model}
Regression method are mainly used to predict stock price or its changing amount in combined system.

\subsubsection{Linear Regression}
Linear regression can be defined using the following equation,
\begin{equation}
	y=w^Tx + \varepsilon
\end{equation}
$ w $ is called \emph{weights}, and $ x $ is features vector, y is target variable, and $ \varepsilon $ is called error term. One example of linear regression can be found in figure~\ref{fg:linear_regression}. This algorithm assumes that the relationship between features and label follows a linear model.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{Linear-regression}
	\caption{Example of simple linear regression with one variable}
	\label{fg:linear_regression}
\end{figure}


There are a large number of procedures which have been developed for parameters estimation and inference in linear regression. Spark MLlib uses least-square estimation\cite{7_mllib_linear_methods}.\\


Given a training set $ (x, y) $ (set number is $ n $), and initial weights $ w $, the error is computed as
\begin{equation}
error := \frac{1}{2} (w^T x - y)^2.
\label{eq:error_equation}
\end{equation}
This type of error is known as mean squared error (MSE).\\

After known the error, next step is using \emph{gradient descent} algorithm to update weight with the equation,
\begin{equation}
w_i=w_i-\alpha \frac{\partial}{\partial w_i} error
\label{eq:update_equation}
\end{equation}
Here $ \alpha $ is called learning rate.

From above equation we can get that,
\begin{equation}
\begin{split}
\frac{\partial }{\partial w_i} error & = \frac{\partial }{\partial w_i} \frac{1}{2}(w^Tx-y)^2\\
& = 2 \cdot \frac{1}{2} (w^Tx-y) \cdot \frac{\partial }{\partial w_i} (w^Tx-y)\\
& = (w^Tx-y) * \frac{\partial }{\partial w_i} (\sum_{j=0}^{n}w_j x_j - y)\\
& = (w^Tx-y)x_i
\end{split}
\label{eq:partil_error}
\end{equation}

Then the updating rule becomes
\begin{equation}
w_i = w_i + \alpha (w^Tx-y)x_i
\end{equation}

This is gradient descent, also called batch gradient descent, the illustration is as figure~\ref{fg:gradient_descent}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{steepest-descent}
	\caption{Illustration of gradient descent (Image source: \url{http://www.holehouse.org/mlclass/17_Large_Scale_Machine\_Learning.html})}
	\label{fg:gradient_descent}
\end{figure}

This algorithm runs very slow for a large data set input, as in every iteration, the errors of every data pair should be calculated\cite{2_ruder_2016}.\\

Spark MLlib use \emph{stochastic gradient descent (SGD)} to speed up the training process\footnote{As shown in its official document, \url{ http://spark.apache.org/docs/latest/mllib-linear-methods.html}}.\\

The core idea of stochastic gradient descent (SGD) is that updating parameters according to the gradient of the error with respect to that a small sample of training example (even one) instead of the whole data set\cite{2_ruder_2016}. The illustration of SGD can be found in figure~\ref{fg:SGD}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{sgd}
	\caption{Illustration of stochastic gradient descent (SGD) (Image source: \url{http://www.holehouse.org/mlclass/17_Large_Scale_Machine_Learning.html})}
	\label{fg:SGD}
\end{figure}
Usually, SGD gets $ w $ "close" to the optimal solution more faster than batch gradient descent, (but may never reach that solution), which makes SGD more suitable to large scale data regression.\\

However, the amount of data in this study is far away from large scale. Even trace back to 10 years, there are only about 2500 transaction days, whose data size is still very small compared with the recommend data size in sklearn's document\footnote{In http://scikit-learn.org/stable/modules/sgd.html}.\\

In this study, the training iterations of our linear regression model are set to 100000, while the learning rate is 0.001.

\subsubsection{Linear Support Vector Machines (SVMs)}
Support Vector Machines (SVMs) was developed by Vladimir Vapnik\cite[p.~105]{4_kantardzic} and is one of the most popular supervised learning methods. This study uses SVM to solve the classification of stock change direction, a typical 2-class classification problem.\\


Without loss of generality, let's using a simple 2-D example to illustrate this problem. Assume we have a set of data, and we want to classify them into two categorical classes. As figure~\ref{fg:SVM} shows, there exits two possible parting lines with different boundary sizes. Are these decision boundaries equally good?
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{svms}
	\caption{Illustration of service vector machines (Image source: \url{https://de.wikipedia.org/wiki/Support_Vector_Machine})}
	\label{fg:SVM}
\end{figure}
The main idea of SVM is: "The decision boundary should be as far away as possible from the data points of both class"\cite[p.~107]{4_kantardzic}. Based one the above idea, A is a better parting line than B (in figure~\ref{fg:SVM}).\\


Mathematica description is as follows\cite[Section~4.5]{4_kantardzic}. Given a classification problem with a training set $ D $, belongs to two classes (using binary with -1 and 1)
\begin{equation}
D={(x_1,y_1),(x_2,y_2),\dots,(x_n,y_n)},x\in R^n, y\in{-1, 1},
\end{equation}
The hyperplane can be represented as
\begin{equation}
w \cdot x-b=0
\end{equation}
This means that
\begin{align*}
w \cdot x_i-b>0,& \text{if $y_i = 1$}\\
w \cdot x_i-b<0,& \text{if $y_i = -1$}
\end{align*}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{SVMHyperplane}
	\caption{A separating hyperplane $ (w, b) $ for 2-D data (Image source: \url{https://de.wikipedia.org/wiki/Support_Vector_Machine})}
	\label{fg:SVMHyperplane}
\end{figure}

To make things clear, in figure~\ref{fg:SVMHyperplane}, two hyperplanes are added where $ w \cdot x_i-b $ equal -1 (on the lower right) and +1 (on the upper left). Thus, the constraint can be represented by
\begin{equation}
y_i(w\cdot x_i-b)\ge 1, i=1,\dots,n
\end{equation}

Geometrically, the distance between these two hyperplanes is $ \frac{2}{\lVert w \rVert} $, to maximize the distance, we need to minimize $ \lVert w \rVert $. Then the question turn out to be a optimization problem. The classifier can then be constructed as:
\begin{equation}
f(x)=sign(w\cdot x - b)
\end{equation}
Obviously, the distance between two hyperplanes is determined by the those $ x_i $ which is lied nearest to the max-margin hyperplane. These $ x_i $ are called \emph{support vectors (SVx)}.\\

However, in real-world applications, there are the cases where subsets cannot be completely separated (like figure~\ref{fg:SVM_soft})\cite[p.~113]{4_kantardzic}. In other words, the algorithm would find a balance between maximizing the margin and minimizing the classifications error during optimization process.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{svm_soft}
	\caption{Soft margin of SVMs}
	\label{fg:SVM_soft}
\end{figure}

\subsubsection{Logistic Regression}
Logistic is also a widely used method to predict binary responses. Rather than predicting the value of the dependent variable in linear regression, logistic regression method estimates the probability that the dependent variable will choose from a given range\cite[Section~5.6, p.~157--158]{4_kantardzic}.

 
Logistic regression takes probabilities of every label into consideration. Suppose that output Y has two possible values, 0 and 1. In training set, the possibilities can be expressed as: $ P(y_i=0)=1-p_i $ and $ P(y_i=1)=p_i $, then the \textit{linear logistic model} can be represented by~\cite[Section~5.6, p.~157--158]{4_kantardzic},
\begin{equation}
	\log (\frac{p_i}{1-p_i}) = b + w^T \cdot x_i
\end{equation}
The reason for using the logit form of output is to prevent the model from generating a result out-range of $ [0, 1] $\\


In this system, logistic regression algorithm are mainly used to predict the changing direction of stock price.

\subsection{Random Forest}
Random forest algorithm was first created by Breiman and is based on decision trees\cite{lauretto2013evaluation}. To reduce the risk of over-fitting, random forests composes of a number of individual decision trees, and this is also where this method get its name from (as figure~\ref{fg:decision-tree} shows).
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{random-forest}
	\caption{Illustration of random forest}
	\label{fg:decision-tree}
\end{figure}

Random Forest can solve both classification and regression problems. For the former problem, every decision tree's prediction is counted as a vote for one class, and the final result is the class that received most votes (like figure~\ref{fg:decision-tree}). For the later question, final result this the average of all decision trees' prediction value.\\


As every decision tree are trained and predicted separately, they can work in parallel, which makes random forest a very suitable algorithm for distributed computing.


\subsection{Artificial Neural Network (ANN)}
Neural networks was first inspired by human nervous system which is made up of neurons, a information processing unit (figure~\ref{fg:neural-nework}). Every neuron receive signals from input or former neurons, then compute them with the activation function and send its result to output or latter neurons\cite[p.~200]{4_kantardzic}.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{neural_network}
	\caption{Illustration of Artificial Neural Network with one hidden layer}
	\label{fg:neural-nework}
\end{figure}

This dissertation uses feed-forward, multilayer perceptron, and back propagation ANN. The following sections introduce the meaning of these ANN types and summarize the process in this study.

\subsubsection{Feed-forward Neural Network}
The term ``feed-forward'' refers to the architecture of neural networks, in which neurons are only connected forward, i.e. every neuron only receives from input or former layer and no connection back\cite[p.~125]{heaton2008introduction}. The overall structure can be regarded as a sequence of repeated computations from input to the output (as figure~\ref{fg:FFNN} shows).
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{DataMining/MultiLayerNeuralNetwork}
	\caption{Feed-forward Neural Network (Image sources: \url{http://technobium.com/stock-market-prediction-using-neuroph-neural-networks/})}
	\label{fg:FFNN}
\end{figure}

\subsubsection{Recurrent Neural Network}
Feed-forward is a very sample architecture, while recurrent neural network (RNN), on the other hand, is much more complicated and is more similar to real biological nervous system. This architecture has feedback from outputs or hidden layers back into earlier layers through a buffer\cite[p.~91]{1_shadbolttaylor_2002}. In this method, current results can affect future predictions, i.e., the prediction of this type neural network takes its past forecasts into consideration. This study does not focuses on this type of neural network is because we can use technical indicators to get the previous stock price information. So there is no need to dive into this complicated structure.

\subsubsection{Multilayer Perceptron (MLP)}

\textit{Multilayer Perceptron} (MLP) neural networks are one of the most important and most popular classes of ANNs\cite[p.~213, Section~7.5]{4_kantardzic}. Typically, this network consists of a set of input nodes as input layer, one or more hidden layers of computational nodes, and a set neurons as output layer (as figure~\ref{fg:FFNN} and~\ref{fg:neural-nework} shows).\\

The model of each neuron in MLP network usually includes a nonlinear activation function. In this study uses sigmoid function (introduced in section~\ref{subsubsec:sigmoid})

The more hidden layers and the larger number of nodes in each hidden layer, the more complicated and powerful the MLP networks can be trained and also the more computing capability is needed. To balance the training cost and prediction accuracy, this dissertation uses a two-hidden-layer MLP network.

\subsubsection{Back Propagation (BP) Algorithm}
Back Propagation (BP) algorithm is based on error-correction learning, and help the MLP networks to adjust its weights to minimize the error\cite[p.~214--218]{4_kantardzic}.\\

BP consists of two phases: a forward pass and a backward pass. In the former phase, a training sample is applied to the input layer, and its output is calculated based on fixed weights. Then the difference between output and target is regarded as error and used in backward pass to update weights. The steps of algorithm can be described as follow\cite{nayak2014impact}:
\begin{enumerate}
	\item \textit{Initialize weights $ w $ with a small random value}. Suppose layer $ j $ has $ m $ nodes, layer $j + 1$ has $ n $ nodes, then the weight matrix between these two layer $ w_{jj+1} $ should have $ m \times n $.
	\item \textit{Forward pass}. The values of every layer $ i $ remark as $ l_i $ (Input as $ l_i =l_1 $, output as $l_o=l_n$, suppose there are n layers in total), the node $ k $ in $ l_j $ remark as $ l_jk $. Given the activation function
	\begin{equation}
	f(l) = \frac{1}{1+e^{-l}}
	\end{equation}
	the value of layer $ i + 1 $ is calculated by,
	\begin{equation}
	l_{i+1}=f(w_{ii+1}^T\cdot l_i)
	\end{equation}
	From the input layer, do this calculation. Record those values as $ l = [l_i, l_2, \ldots, l_o] $.
	\item \textit{Backward pass and weights update} 
	\begin{enumerate}
		\item Get the error value using
		\begin{equation}
		\delta_n = y - l_n
		\end{equation}
		
		\item For the following layers, using formula,
		\begin{equation}
		\delta_j = w_{jj+1}^T\delta_{j+1}\cdot f'(l_i)
		\end{equation}
		where $ f'(l) = f(l)(1-f(l)) $
		
		\item Update weights.
		\begin{equation}
		w_{ii+1} = w_{ii+1} + \alpha \delta_i 
		\end{equation}
	\end{enumerate}
\end{enumerate}

The above algorithm is very similar to a typical batch gradient descent process. As data amount is relatively small (e.g. 1 year only have around 250 transaction days), using this method is much faster to reach the optimal solution than use a training process much like SGD.

