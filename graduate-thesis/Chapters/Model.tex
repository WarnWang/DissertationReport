\chapter{System Design And Parameters}
\label{ch:system}

The objective of this dissertation is to build an automatic system which can download raw data, do transformation, train model, and give prediction result. This system is based on Python, a Friendly power programming language. “Quandl”, “TA-Lib”, “SciPy”, “pySpark”, “SciPy-learner” are used for data collecting, mining analysis and handling times series data structure. The whole process can be found in figure~\ref{fg:system_model}.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{FlowChart}
	\caption{Flow Chart of the whole system}
	\label{fg:system_model}
\end{figure}

After collected all raw data, system would split it into two parts, training and testing (details about collected data is introduced in Chapter\ref{ch:market}). To make an convincing experiment, \emph{the date of all testing data is behind that of training data}, so that the system would have no knowledge of the testing data. Let's talk about the details of data processing and model training process next.\\


\section{Data Processing}
The data processing part include data normalization and PCA. Feature vectors of testing and training data, labels of training data should be normalized, technique details are introduced in Chapter~\ref{ch:mining}.\\


Feature vectors transform process are,
\begin{enumerate}
	\item Train a data normalizer (Min Max Normalization) and translate training features into normalized data.
	\item Train a PCA transformer using step 1's output, and transform those data.
	\item Train a second data normalizer (also Min Max Normalization) and translate step 2's output into processed data.
	\item Use the same transformer in step 1-3 to transform testing features step by step.
\end{enumerate}

The label data process only handles training data, there are two types of transform method based on the model used in next step,
\begin{itemize}
	\item If training model is single learning algorithm, i.e., the model are used to predict the stock price directly. Then the label is normalized based on the high and low price of last five days,
	\begin{equation}
		label'=\frac{label*2-(high + low)}{high - low}
	\end{equation}
	\item If training model is the combine of two learning algorithm, i.e., one is used to predict change direction, the other is to forecast amount. The trend label is transformed with,
	\begin{equation}
	trend=\begin{cases}
	1 & \text{ if } price_{tomorrow} > price_{today} \\ 
	0 & \text{ if } otherwise
	\end{cases}
	\end{equation}
	The amount label is calculated by,
	\begin{equation}
	amount=\left | price_{tomorrow} - price_{today} \right |
	\end{equation}
	and after the above calculation, the amount value will be normalized using standard normalization algorithm. 
\end{itemize}

After the above process, data is transformed and can be used for model training.


\section{Training and Predict}
As described before, there are two learning method used in this dissertation. 
\begin{itemize}
	\item Using one single algorithm to predict the stock price directly. Such algorithms include Linear Regression, Random Forest and ANN
	\item A combination of two learning method, using one algorithm to predict change direction (Logistic Regression, Random Forest and SVM), another to forecast amount (Linear Regression, Random, Forest and ANN). The two method works separately, and the predict result is the combination of both model.
\end{itemize}

On each iteration, system would randomly subsample the origin training dataset to get a different training set (a.k.a. bootstrapping). If the training algorithm does not support re-training (like Random Forest and SVM in pyspark.mllib), then the best model would be picked. Otherwise, just re-train the former model.\\


After training, the system would get a model then uses it to predict from testing dataset.

\section{Detail Parameters of every training method}
Details of the parameters can be found in Table~\ref{tb:parameters}

\begin{table}[h]
	\centering
	\begin{tabular}{|l|l|l|}
		\hline
		\multicolumn{1}{|c|}{\textbf{Algorithm}} & \multicolumn{1}{c|}{\textbf{Parameters}} & \multicolumn{1}{c|}{\textbf{Optimize Method}} \\ \hline
		\textbf{\begin{tabular}[c]{@{}l@{}}Random Forest\\ (Classifier \& Regressor)\end{tabular}} & \begin{tabular}[c]{@{}l@{}}Trees Number: 40\\ Max Depth: 20\end{tabular} & NA \\ \hline
		\textbf{SVM} & \begin{tabular}[c]{@{}l@{}}Iterations: 100000\\ Learning rate: 0.001\end{tabular} & SGD \\ \hline
		\textbf{Logistic Regression} & \begin{tabular}[c]{@{}l@{}}Iterations: 100000\\ Learning rate: 0.001\end{tabular} & SGD \\ \hline
		\textbf{Linear Regression} & \begin{tabular}[c]{@{}l@{}}Iterations: 100000\\ Learning rate: 0.001\end{tabular} & SGD \\ \hline
		\textbf{ANN} & \begin{tabular}[c]{@{}l@{}}Iterations: 15\\ Learning rate: 0.0001\end{tabular} & BGD \\ \hline
	\end{tabular}
	\caption{Parameters of Every learning method}
	\label{tb:parameters}
\end{table}


The neural network is a four-layer (two hidden layer) model. A two-layer model is just same as linear regression. The reason for choosing 2 hidden layers is that "can represent an arbitrary decision boundary to arbitrary accuracy with rational activation functions and can approximate any smooth mapping to any accuracy"\cite{heaton2008introduction}.\\


To determine the number of neurons use in the hidden layers, Jeff Heaton also wrote in \cite{heaton2008introduction} that "The number of hidden neurons should be between the size of the input layer and the size of the output layer". So, in this study, the nodes number of the first hidden layer is $ \frac{2}{3} $ of that of the input layer, and that of the second is $ \frac{1}{3} $ of that of the input layer.\\


For the normalization method, the range of min-max normalizer is $ [-1, 1] $.
