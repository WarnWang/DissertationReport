\documentclass[12pt,a4paper]{scrartcl}
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{url}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\pagestyle{fancy}
\cfoot{\thepage}
\title{Interim report}
\subtitle{Distributed financial data forecaster}
\author{Wang Youan\\{\small Supervised by: YIP Chi Lap}}
\date{\today}
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}
\bibliographystyle{abbrv}
\graphicspath{{images/}}
\setlength{\parindent}{15pt}
\begin{document}
	\maketitle
	\section{Introduction}
	It is human beings' common goal to make life easier and more comfortable. Wealth can bring help to achieve this goal. That's why there are so many works done to predict the stock price. As being a complex (non-linear) and volatile system with many factors (such as companies' performance, domestic economies, festivals, seasons, etc.)\cite{chen1986economic}, stock market is difficult to predicted daily behaviors, so as to the day-to-day stock price changes. Besides, those factors usually have relationship with each other, and they will keep changing all the time. Hence, investors and fund manager must maintain real-time monitoring of market behavior, so as to make the right trading decision.\\
	\indent With the development of machine learning and cloud computing technologies, people find a new way to analyze many factors of stock price at a time without too much manual cost. There are many works towards prediction have been attempted, includes neural network\cite{kimoto1990stock,naeini2010stock}, multi-class support vector machine\cite{kercheval2015modelling}, linear and polynomial regression\cite{nunnostock,alexanderstock}, random forest\cite{alexanderstock,lauretto2013evaluation}.
	\section{Objectives}
	In this study, I will try to build a automatic learning model combining linear regression, random forests and technical, fundamental analysis together to predict stock price and trends. This model will be running on a distributed system (Apache Spark\cite{apache_spark}) which could collect financial data and can be used to predicted real time finally.
	\section{Methods}
	From "Efficient Market Hypothesis"\cite{basu1977investment,sewell2011history,vacha2005dynamical}, we can find that the changes of stock price follows a random walk which could be explained via Brownian motion techniques. I decide to use the following method to simulate such motion.
	\subsection{Stochastic gradient descent}
	\textbf{Stochastic Gradient Descent (SGD)} is a simple but efficient approach to solve supervised learning problem on large scale\cite{bottou2010large}, which makes it very suitable to be used for long term price prediction. The model of loss in my model is \cite{spark_documentation},
	\begin{equation}
		\label{eq:SGD}
		L(w;x,y):=\frac{1}{2}(w^Tx-y)^2
	\end{equation}
	Where L is loss, $ x $ is the input vector and $ w $ is the weight vector.
	\subsection{Random Forest}
	Random Forest is a special type of decision trees and was first introduced by Leo Breiman \cite{breiman2001random}. This algorithm constructs a multitude of decision trees at training time and outputs the mean prediction of those individual trees. This methods is designed to eliminate the overfitting of decision trees.
	\subsection{Apache Spark}
	Apache Spark, which is first developed at the UC Berkeley AMPLab and has been contributed to the Apache Software Foundation, is a fast and general engine for large-scale data processing\cite{ryza2015advanced}. Spark inherits MapReduce's linear scalability and fault tolerance, and extends it in three ways,
	\begin{itemize}
		\item First, instead relying on a map-then-reduce format, Spark executes operators using directed acyclic graph (DAG), which means that while MapReduce must write intermediate results to the file system, Spark can transmit them directly to the next step. This makes Spark much faster.
		\item Second, highly accessible. Spark offers simple APIs in Python, Java, Scala, SQL and R. Besides, users can use it interactively from the Scala, Python and R shells. Those features make Spark more easy to use.
		\item Third, Spark integrates closely with other Big Data tools. For example, \enquote{Spark can run on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3}\cite{apache_spark}.
	\end{itemize}
	\section{Works has been done}
	Before the end of April 2016, I've finish the below works,
	\subsection{Distributed System Deploy}
	I use 3 virtual machines, each have 2G RAM and a vcore,
	\begin{figure}[h]
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{environments}
			\caption{Virtual Machines}
			\label{fig:vm}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.8\linewidth]{spark_deploy}
			\caption{Spark Web UI}
			\label{fig:spark}
		\end{subfigure}
		\caption{Environment of my Cluster}
		\label{fig:environment}
	\end{figure} 
	\subsection{Financial Data Collect and Clean}
	\subsection{Dissertation Website}
	\subsection{Basic Strategy}
	\subsection{Data Normalization}
	\section{Future Works}
	\bibliography{Interim_report}
\end{document}